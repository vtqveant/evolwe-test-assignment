    Задача
---------------

мы предлагаем следующее задание:

существует задача code search, конкретно датасет CodeSearchNet, мы предлагаем повторить или приблизиться к результатам
модели вот этой статьи https://arxiv.org/pdf/2110.07811.pdf
мы ожидаем, что Вы напишете код, на котором коллеги смогут оценить Ваш уровень владения современными моделями
векторных представлений


    Tasks
--------------

July 15:
    [1.] Поднять CodeBERT для инференса
    [2.] подготовить параллельный корпус CodeSearchNet + preprocessed dataset из CasCode (см. "Непонятное №3")
    [3.] Поднять k-NN search engine как сервис (можно на отдельной машине), см. тж. Vearch https://vearch.github.io/
       (NB: vearch memory-only поддерживает до 10M векторов на одной машине); Weaviate; OpenSearch has a kNN feature
       (https://opensearch.org/)

July 16:
    [3.5] обернуть датасет в генератор
    [4.] посчитать эмбединги для PL (code snippets) из CodeSearchNet с помощью CodeBERT и сложить их в OpenSearch
        NB: для вычисления candidate set мы строим входную последовательность в виде [CLS] PL1 PL2 PL3 [SEP],
            т.е. без NL-фрагмента (хотя CodeBERT обучался на парах NL-PL!!!). Есть сомнения, что это вообще корректно,
            но все претензии к статье про CasCode
        - состояние в докере -- нужно делать снэпшот контейнера! OpenSearch тут не при чем
    [5]. после загрузки данных в OpenSearch нужно обучить индекс - не нужно!
    [6.] НЕ ДЕЛАЛ -- [OPTIONAL] взять реализацию метрики MRR из CodeBERT/codesearch и с её помощью посчитать baseline по схеме
       "cosine similarity как критерий ранжирования" для pl по nl как запросу -- это будет baseline

July 17:
    7. написать MLP-классификатор поверх CodeBERT для пар (nl, pl) с cross-entropy loss и обучить его на CodeSearchNet
        NB: здесь уже строим поноценные пары NL-PL для всех кандидатов из candidate set!
    7.5 Порефачить подготовку датасета: кандидаты на тесте должны выбираться из candidate codes, их число
        не совпадает с числом testing queries !!! Т.е. сейчас кандидаты выбираются из неправильного множества!!!
    [8.] (первая часть CasCode) написать извлечение top-k pl по cosine similarity из OpenSearch по nl как запросу
    9. (вторая часть CasCode) посчитать вероятность принадлежности положительному классу с помощью MLP-классификатора
        для пары (nl, pl) по всем pl из top-k, использовать эту вероятность как критерий ранжирования top-k,
        по полученным рангам посчитать MRR -- это будет мой финальный результат


    Непонятное
------------------

1. Как получить embedding из CodeBERT для всего NL/PL целиком
      Ответ: The output of CodeBERT includes (1) contextual vector representation of each token, for both natural language
   and code, and (2) the representation of [CLS], which works as the aggregated sequence representation. (CodeBERT paper, p. 3)
   [CLS] is a special token in front of the two segments, whose final hidden representation is considered as the aggregated
   sequence representation for classification or ranking. (idib.)

2. Какая размерность у этого embedding-а? (Это нужно для FAISS/Vearch/Weaviate...)

        768 = 3 * 2^8

3. Сколько должно быть векторов всего (для обучения и для eval, чтобы сравнить потом с CasCode)

       (из CasCode paper, pp. 5-6, таблица идентична таблице в файле CodeBERT/GraphCodeBERT/codesearch/README.md)

       Our pre-processing and train-val-splits are identical to the setting from Guo et al. (2021) = CodeBERT/GraphCodeBERT
       who filter low-quality queries and expand the retrieval set to make the code search task more challenging and realistic.

                                     Go      Java        JS       PHP     Python      Ruby
       Training examples        167,288   164,923    58,025   241,241    251,820    24,927
       Dev queries                7,235     5,183     3,885    12,982     13,914     1,400
       Testing queries            8,122    10,955     3,291    14,014     14,918     1,261
       Candidate codes           28,120    40,347    13,981    52,660     43,827     4,360

       таблица идентична таблице в файле CodeBERT/GraphCodeBERT/codesearch/README.md
       там же инструкции, как построить этот датасет

       Всего 1,188,679 векторов размерности 768

       !!! Кандидаты на тесте должны выбираться из candidate codes, их число не совпадает с числом testing queries!!!

4. Как будет (и будет ли вообще) происходить дообучение BERT-а с MLP-классификатором, если все входные embeddings будут
   предпосчитаны по сути (и лежать в индексе/FAISS)? В CasCode, получается, embeddings зафиксированы?

5. Еще получается, что embeddings для NL/PL (репрезентация на основе CLS) вовсе не контекстная, а одна и неизменная
   для всей строки (NL/PL)

6. Получается, что при обучении CodeBERT+MLP обучается на одних векторах для PL, а предиктит на других?